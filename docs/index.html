---

title: CLOOB Conditioned Latent Denoising Diffusion GAN


keywords: fastai
sidebar: home_sidebar

summary: "My code and utilities for training CCLDDGs."
description: "My code and utilities for training CCLDDGs."
nb_path: "index.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: index.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is very much a work in progress. Stay tuned for better info soon :)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Install">Install<a class="anchor-link" href="#Install"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>At the moment I'd suggest cloning this and adding it to your path.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="What-is-all-this">What is all this<a class="anchor-link" href="#What-is-all-this"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The main thing this code does is define a UNet architecture and an accompanying Discriminator architecture that can take in an image (or a latent representation of one) along with conditioning information (what timestep we're looking at, a CLOOB embedding of an image or caption) and a latent variable <code>z</code> used to turn the unet into a more GAN-like multimodal generator thingee.</p>
<p>Coming soon, demos of this as</p>
<ul>
<li>A standard diffusion model</li>
<li>A standard latent diffusion model</li>
<li>A standard Defusion Denoising GAN</li>
<li>A latent Defusion Denoising GAN</li>
<li>CLOOB-Conditioned Latent Defusion Denoising GAN</li>
<li>Training a text-to-image model with no text</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="mi">3</span><span class="o">+</span><span class="mi">5</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>8</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Running-the-training-script">Running the training script<a class="anchor-link" href="#Running-the-training-script"> </a></h1><p>This script is written to run OUTSIDE this directory (aka NOT in cclddg). It also assumes the locations of various dependancies and model files. To set it up, in a notebook run:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># !git clone https://github.com/CompVis/latent-diffusion                           &amp;&gt;&gt; install.log</span>
<span class="c1"># !git clone https://github.com/CompVis/taming-transformers                        &amp;&gt;&gt; install.log</span>
<span class="c1"># !pip install -e ./taming-transformers                                            &amp;&gt;&gt; install.log</span>
<span class="c1"># !git clone --recursive https://github.com/crowsonkb/cloob-training               &amp;&gt;&gt; install.log</span>
<span class="c1"># !git clone https://github.com/openai/CLIP/                                       &amp;&gt;&gt; install.log</span>
<span class="c1"># !pip install CLIP/.                                                              &amp;&gt;&gt; install.log</span>
<span class="c1"># !pip install --upgrade webdataset ipywidgets                                     &amp;&gt;&gt; install.log</span>
<span class="c1"># !pip install datasets omegaconf einops wandb pytorch_lightning                   &amp;&gt;&gt; install.log</span>
<span class="c1"># !wget https://ommer-lab.com/files/latent-diffusion/kl-f8.zip                     &amp;&gt;&gt; install.log</span>
<span class="c1"># !unzip -q kl-f8.zip  </span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then if you wish to use W&amp;B for logging, run <code>wandb login</code> in a terminal.</p>
<p>Then copy the script from the cclddg folder downloaded as part of the command above to your local dir:</p>
<p><code>cp cclddg/train_cclddg.py train.py</code></p>
<p>And run your training like so:</p>
<p><code>python train.py --z_dim 16 --n_channels_unet 64 --batch_size 64 --n_batches 20 --lr_gen 0.0001 --lr_disc 0.0001 --log_images_every 50 --save_models_every 500 --n_steps 8 --dataset celebA --wandb_project cclddg_faces</code></p>

</div>
</div>
</div>
</div>
 

