{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452022dd-a172-44ed-86d3-d9d03af17b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp ddg_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be6f21b-29f1-4d06-a8db-646828688a3c",
   "metadata": {},
   "source": [
    "# Denoising Diffusion GAN Context\n",
    "> Managing admin around the DDG training and sampling process.\n",
    "\n",
    "Add more explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bab80e-b182-45d0-bd7c-05b77e05dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc32b126-d6a1-443f-ba3f-0137f2b96820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class DDG_Context():\n",
    "    \"\"\"TODO docstring\"\"\"\n",
    "    def __init__(self, n_steps=5, beta_min=0.3, beta_max=0.9, device='cpu'):\n",
    "        self.n_steps = n_steps\n",
    "        self.beta = torch.linspace(beta_min, beta_max, n_steps).to(device)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
    "        \n",
    "    def gather(self, consts: torch.Tensor, t: torch.Tensor):\n",
    "        \"\"\"Gather consts for $t$ and reshape to feature map shape\"\"\"\n",
    "        c = consts.gather(-1, t)\n",
    "        return c.reshape(-1, 1, 1, 1)\n",
    "\n",
    "    def q_xt_xtminus1(self, xtm1, t):\n",
    "        \"\"\"A single noising step:\"\"\"\n",
    "        mean = self.gather(1. - self.beta, t) ** 0.5 * xtm1 # √(1−βt)*xtm1\n",
    "        var = self.gather(self.beta, t) # βt I\n",
    "        eps = torch.randn_like(xtm1) # Noise shaped like xtm1\n",
    "        return mean + (var ** 0.5) * eps, eps\n",
    "\n",
    "    def q_xt_x0(self, x0, t):\n",
    "        \"\"\"Jump to a given step\"\"\"\n",
    "        mean = self.gather(self.alpha_bar, t) ** 0.5 * x0 # now alpha_bar\n",
    "        var = 1-self.gather(self.alpha_bar, t) # (1-alpha_bar)\n",
    "        eps = torch.randn_like(x0)\n",
    "        return mean + (var ** 0.5) * eps, eps\n",
    "    \n",
    "    def p_xt(xt, noise, t):\n",
    "        \"\"\"The reverse step, not used in DDG\"\"\"\n",
    "        alpha_t = self.gather(self.alpha, t)\n",
    "        alpha_bar_t = self.gather(self.alpha_bar, t)\n",
    "        eps_coef = (1 - alpha_t) / (1 - alpha_bar_t) ** .5\n",
    "        mean = 1 / (alpha_t ** 0.5) * (xt - eps_coef * noise) # Note minus sign\n",
    "        var = self.gather(self.beta, t)\n",
    "        eps = torch.randn(xt.shape, device=xt.device)\n",
    "        return mean + (var ** 0.5) * eps \n",
    "    \n",
    "    def tensor_to_image(self, t):\n",
    "      return Image.fromarray(np.array(((t.detach().cpu().squeeze().permute(1, 2, 0)+1)/2).clip(0, 1)*255).astype(np.uint8))\n",
    "    \n",
    "    # Examples with some propmts\n",
    "    def examples(self, ae_model, unet, cloob, n_examples=12, cfg_scale_max=4,\n",
    "             prompts = [\n",
    "                'A photograph portrait of a man with a beard, a human face',\n",
    "                'Green hills and grass beneath a blue sky',\n",
    "                'A watercolor painting of an underwater submarine',\n",
    "                'A car, a photo of a red car',\n",
    "                'An armchair in the shape of an avocado',\n",
    "                'blue ocean waves',\n",
    "                'A red stop sign'],\n",
    "             img_size=128, z_dim=8,\n",
    "            ):\n",
    "        \"\"\"Given ae_model, a u_net and cloob, produce some example images with CFG.\"\"\"\n",
    "        \n",
    "        device = ae_model.device\n",
    "        cfg_scale = torch.linspace(0, cfg_scale_max, n_examples).to(device)\n",
    "\n",
    "        im_out = Image.new('RGB', (img_size*n_examples, img_size*len(prompts)))\n",
    "\n",
    "        for i, p in enumerate(prompts):\n",
    "            z = torch.randn((n_examples,z_dim), device=device)\n",
    "            c = cloob.text_encoder(cloob.tokenize([p]*n_examples).to(device)).float()\n",
    "            c_neg = torch.zeros((n_examples,512), device=device)\n",
    "            x = torch.randn(n_examples, 4, img_size//8, img_size//8).to(device)\n",
    "            t = torch.ones((n_examples,), dtype=torch.long).to(device)*self.n_steps\n",
    "            while t[0] > 0:\n",
    "                pred_im_pos = unet(x.float(), t, c, z)\n",
    "                pred_im_neg = unet(x.float(), t, c_neg, z)\n",
    "                pred_im = pred_im_neg + (pred_im_pos-pred_im_neg)*cfg_scale.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).expand(-1, 4, img_size//8, img_size//8)\n",
    "                x, n = self.q_xt_x0(pred_im, t-1)\n",
    "                t -= 1\n",
    "                if t[0]==0:\n",
    "                    for s in range(n_examples):\n",
    "                        im_out.paste(self.tensor_to_image(ae_model.decode(pred_im[s].unsqueeze(0))), (img_size*s, img_size*i))\n",
    "\n",
    "        return im_out   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028295bb-77e8-4920-815f-192dc970f08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 4, 16, 16]), torch.Size([8, 4, 16, 16]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddg = DDG_Context()\n",
    "x0 = torch.randn(8, 4, 16, 16)\n",
    "t = torch.randint(0, 4, (8,), dtype=torch.long)\n",
    "x_t, n_t = ddg.q_xt_x0(x0, t)\n",
    "x_t.shape, n_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe56f8c-e2a3-4530-ab90-2b109d78079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: return noise optional\n",
    "# TODO: explain what this is :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9099fbd9-4313-4d92-9f3a-3673518987d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO random t convenience function\n",
    "# TODO p_xt_xtm1 for non-DDG diffusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
