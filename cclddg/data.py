# AUTOGENERATED! DO NOT EDIT! File to edit: ../02_Datasets.ipynb.

# %% auto 0
__all__ = ['tensor_to_image', 'CelebADataset', 'get_celebA_dl', 'ImageWoof', 'get_imagewoof_dl', 'get_cc12m_dl',
           'get_paired_vqgan']

# %% ../02_Datasets.ipynb 3
from PIL import Image
import numpy as np
def tensor_to_image(t):
    return Image.fromarray(np.array(((t.detach().cpu().squeeze().permute(1, 2, 0)+1)/2).clip(0, 1)*255).astype(np.uint8))

# %% ../02_Datasets.ipynb 4
from datasets import load_dataset
from torchvision import transforms as T
from torch.utils.data import Dataset, DataLoader

class CelebADataset(Dataset):
    """One option: custom Dataset class"""
    def __init__(self, img_size=128):
        self.dataset = load_dataset('huggan/CelebA-faces')['train']
        self.preprocess = T.Compose([T.ToTensor(),T.Resize(img_size), T.CenterCrop(img_size)])
    def __len__(self):
        return len(self.dataset)
    def __getitem__(self, idx):
        x = self.dataset[idx]
        return (self.preprocess(x['image']), 'A photo of a face')
        
def get_celebA_dl(img_size=128, batch_size=32):
    dataset = CelebADataset(img_size)
    dl = DataLoader(dataset, batch_size=batch_size)
    return dl

# %% ../02_Datasets.ipynb 8
class ImageWoof(Dataset):
    """One option: custom Dataset class"""
    def __init__(self, img_size=128):
        self.dataset = load_dataset('johnowhitaker/imagewoof2-320')['train'].shuffle()
        self.preprocess = T.Compose([T.ToTensor(),T.Resize(img_size), T.CenterCrop(img_size)])
        # self.dogs = {'Shih-Tzu':155, 'Rhodesian ridgeback':159, 'Beagle':162, 'English foxhound':167, 'Border terrier':182, 'Australian terrier':193,
        #              'Golden retriever':207, 'Old English sheepdog':229, 'Samoyed':258,  'Dingo':273}
        self.dogs = {0: 'Shih-Tzu',
                     1: 'Rhodesian ridgeback',
                     2: 'Beagle',
                     3: 'English foxhound',
                     4: 'Border terrier',
                     5: 'Australian terrier',
                     6: 'Golden retriever',
                     7: 'Old English sheepdog',
                     8: 'Samoyed',
                     9: 'Dingo'}
    def __len__(self):
        return len(self.dataset)
    
    def __getitem__(self, idx):
        x = self.dataset[idx]
        label = x['label']
        text = 'A photo of a ' + self.dogs[int(label)] 
        return (self.preprocess(x['image'].convert('RGB')), text)
        
def get_imagewoof_dl(img_size=128, batch_size=32):
    dataset = ImageWoof(img_size)
    dl = DataLoader(dataset, batch_size=batch_size)
    return dl

# %% ../02_Datasets.ipynb 11
import webdataset as wds
import torch
def get_cc12m_dl(img_size=128, batch_size=32,url=None, num_workers=8):
    if url == None:
        url = 'https://huggingface.co/datasets/laion/conceptual-captions-12m-webdataset/resolve/main/data/{00000..01200}.tar'
    preproc = T.Compose([T.ToTensor(),T.Resize(img_size), T.CenterCrop(img_size)])
    dataset = (
          wds.WebDataset(url)
          .shuffle(1000)
          .decode("pil")
          .rename(image="jpg;png", text="txt")
          .map_dict(image=preproc)
          .to_tuple("image", "text")
    )
    dl = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers)
    return dl

# %% ../02_Datasets.ipynb 15
def get_paired_vqgan(batch_size=32):
    preprocess_image = T.Compose([
        T.ToTensor(),
    ])
    def preprocess(sample):
        return {
            "decoded": preprocess_image(sample["decoded.jpg"]),
            "input": preprocess_image(sample["input.jpg"])
        }
    urls = 'https://huggingface.co/datasets/dalle-mini/vqgan-pairs/resolve/main/data/{00001..00954}.tar'
    dataset = (wds.WebDataset(urls, handler=wds.warn_and_continue)
               .shuffle(2500)
               .decode("pil")
               .map(preprocess)
               .to_tuple("decoded", "input")
               .batched(batch_size))

    dl = wds.WebLoader(
        dataset,
        batch_size=None,
        num_workers=2
    )
    dl = dl.unbatched().batched(batch_size)
    return dl
