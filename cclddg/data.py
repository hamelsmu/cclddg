# AUTOGENERATED! DO NOT EDIT! File to edit: 02_Datasets.ipynb (unless otherwise specified).

__all__ = ['tensor_to_image', 'CelebADataset', 'get_celebA_dl', 'get_cc12m_dl', 'get_paired_vqgan']

# Cell
from PIL import Image
import numpy as np
def tensor_to_image(t):
    return Image.fromarray(np.array(((t.detach().cpu().squeeze().permute(1, 2, 0)+1)/2).clip(0, 1)*255).astype(np.uint8))

# Cell
from datasets import load_dataset
from torchvision import transforms as T
from torch.utils.data import Dataset, DataLoader

class CelebADataset(Dataset):
    """One option: custom Dataset class"""
    def __init__(self, img_size=128):
        self.dataset = load_dataset('huggan/CelebA-faces')['train']
        self.preprocess = T.Compose([T.ToTensor(),T.Resize(img_size), T.CenterCrop(img_size)])
    def __len__(self):
        return len(self.dataset)
    def __getitem__(self, idx):
        x = self.dataset[idx]
        return (self.preprocess(x['image']), 'A photo of a face')

def get_celebA_dl(img_size=128, batch_size=32):
    dataset = CelebADataset(img_size)
    dl = DataLoader(dataset, batch_size=batch_size)
    return dl

# Cell
import webdataset as wds
import torch
def get_cc12m_dl(img_size=128, batch_size=32,url=None, num_workers=8):
    if url == None:
        url = 'https://huggingface.co/datasets/laion/conceptual-captions-12m-webdataset/resolve/main/data/{00000..01200}.tar'
    preproc = T.Compose([T.ToTensor(),T.Resize(img_size), T.CenterCrop(img_size)])
    dataset = (
          wds.WebDataset(url)
          .shuffle(1000)
          .decode("pil")
          .rename(image="jpg;png", text="txt")
          .map_dict(image=preproc)
          .to_tuple("image", "text")
    )
    dl = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers)
    return dl

# Cell
def get_paired_vqgan(batch_size=32):
    preprocess_image = T.Compose([
        T.ToTensor(),
    ])
    def preprocess(sample):
        return {
            "decoded": preprocess_image(sample["decoded.jpg"]),
            "input": preprocess_image(sample["input.jpg"])
        }
    urls = 'https://huggingface.co/datasets/dalle-mini/vqgan-pairs/resolve/main/data/{00001..00954}.tar'
    dataset = (wds.WebDataset(urls, handler=wds.warn_and_continue)
               .shuffle(2500)
               .decode("pil")
               .map(preprocess)
               .to_tuple("decoded", "input")
               .batched(batch_size))

    dl = wds.WebLoader(
        dataset,
        batch_size=None,
        num_workers=2
    )
    dl = dl.unbatched().batched(batch_size)
    return dl